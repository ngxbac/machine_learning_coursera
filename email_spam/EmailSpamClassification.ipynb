{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import PorterStemmer\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file_name):\n",
    "    with open(file_name) as f:\n",
    "        return f.read()\n",
    "\n",
    "def emailFeatures(word_indices):\n",
    "    \n",
    "    # Total number of words in the dictionary\n",
    "    n = 1899;\n",
    "\n",
    "    # You need to return the following variables correctly.\n",
    "    x = np.zeros((n, 1))\n",
    "    x[word_indices, 0] = 1\n",
    "    return x\n",
    "\n",
    "def getVocabList():\n",
    "    #GETVOCABLIST reads the fixed vocabulary list in vocab.txt and returns a\n",
    "    #cell array of the words\n",
    "    #   vocabList = GETVOCABLIST() reads the fixed vocabulary list in vocab.txt \n",
    "    #   and returns a cell array of the words in vocabList.\n",
    "\n",
    "\n",
    "    ## Read the fixed vocabulary list\n",
    "    with open('vocab.txt', 'r') as vocabFile:\n",
    "\n",
    "        # Store all dictionary words in dictionary vocabList\n",
    "        vocabList = {}\n",
    "        for line in vocabFile.readlines():\n",
    "            i, word = line.split()\n",
    "            vocabList[word] = int(i)\n",
    "\n",
    "    return vocabList\n",
    "\n",
    "def processEmail(email_contents):\n",
    "    #PROCESSEMAIL preprocesses a the body of an email and\n",
    "    #returns a list of word_indices \n",
    "    #   word_indices = PROCESSEMAIL(email_contents) preprocesses \n",
    "    #   the body of an email and returns a list of indices of the \n",
    "    #   words contained in the email. \n",
    "    #\n",
    "\n",
    "    # Load Vocabulary\n",
    "    vocabList = getVocabList()\n",
    "\n",
    "    # Init return value\n",
    "    word_indices = []\n",
    "\n",
    "    # ========================== Preprocess Email ===========================\n",
    "\n",
    "    # Find the Headers ( \\n\\n and remove )\n",
    "    # Uncomment the following lines if you are working with raw emails with the\n",
    "    # full headers\n",
    "\n",
    "    # hdrstart = email_contents.find(\"\\n\\n\")\n",
    "    # if hdrstart:\n",
    "    #     email_contents = email_contents[hdrstart:]\n",
    "\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "\n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    email_contents = re.sub('(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "\n",
    "    # Handle $ sign\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "\n",
    "\n",
    "    # ========================== Tokenize Email ===========================\n",
    "\n",
    "    # Output the email to screen as well\n",
    "    print('\\n==== Processed Email ====\\n\\n')\n",
    "\n",
    "    # Process file\n",
    "    l = 0\n",
    "\n",
    "    # Slightly different order from matlab version\n",
    "\n",
    "    # Split and also get rid of any punctuation\n",
    "    # regex may need further debugging...\n",
    "    email_contents = re.split(r'[@$/#.-:&\\*\\+=\\[\\]?!(){},\\'\\'\\\">_<;%\\s\\n\\r\\t]+', email_contents)\n",
    "\n",
    "    for token in email_contents:\n",
    "\n",
    "        # Remove any non alphanumeric characters\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "\n",
    "        # Stem the word \n",
    "        token = PorterStemmer().stem(token.strip())\n",
    "\n",
    "        # Skip the word if it is too short\n",
    "        if len(token) < 1:\n",
    "           continue\n",
    "\n",
    "        # Look up the word in the dictionary and add to word_indices if\n",
    "        # found\n",
    "        # ====================== YOUR CODE HERE ======================\n",
    "        # Instructions: Fill in this function to add the index of str to\n",
    "        #               word_indices if it is in the vocabulary. At this point\n",
    "        #               of the code, you have a stemmed word from the email in\n",
    "        #               the variable str. You should look up str in the\n",
    "        #               vocabulary list (vocabList). If a match exists, you\n",
    "        #               should add the index of the word to the word_indices\n",
    "        #               vector. Concretely, if str = 'action', then you should\n",
    "        #               look up the vocabulary list to find where in vocabList\n",
    "        #               'action' appears. For example, if vocabList{18} =\n",
    "        #               'action', then, you should add 18 to the word_indices \n",
    "        #               vector (e.g., word_indices = [word_indices ; 18]; ).\n",
    "        # \n",
    "        # Note: vocabList{idx} returns a the word with index idx in the\n",
    "        #       vocabulary list.\n",
    "        # \n",
    "        # Note: You can use strcmp(str1, str2) to compare two strings (str1 and\n",
    "        #       str2). It will return 1 only if the two strings are equivalent.\n",
    "        #\n",
    "\n",
    "        idx = vocabList[token] if token in vocabList else 0\n",
    "\n",
    "        # only add entries which are in vocabList\n",
    "        #   i.e. those with ind ~= 0, \n",
    "        #        given that ind is assigned 0 if str is not found in vocabList\n",
    "        if idx > 0:\n",
    "            word_indices.append(idx)\n",
    "\n",
    "        # =============================================================\n",
    "\n",
    "\n",
    "        # Print to screen, ensuring that the output lines are not too long\n",
    "        if l + len(token) + 1 > 78:\n",
    "            print(\"\")\n",
    "            l = 0\n",
    "        print('{:s}'.format(token)),\n",
    "        l = l + len(token) + 1\n",
    "\n",
    "    # Print footer\n",
    "    print('\\n\\n=========================\\n')\n",
    "\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing sample email (emailSample1.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n",
      "\n",
      "==== Processed Email ====\n",
      "\n",
      "\n",
      "anyon\n",
      "know\n",
      "how\n",
      "much\n",
      "it\n",
      "cost\n",
      "to\n",
      "host\n",
      "a\n",
      "web\n",
      "portal\n",
      "well\n",
      "it\n",
      "depend\n",
      "on\n",
      "how\n",
      "mani\n",
      "\n",
      "visitor\n",
      "you\n",
      "re\n",
      "expect\n",
      "thi\n",
      "can\n",
      "be\n",
      "anywher\n",
      "from\n",
      "less\n",
      "than\n",
      "number\n",
      "buck\n",
      "a\n",
      "month\n",
      "\n",
      "to\n",
      "a\n",
      "coupl\n",
      "of\n",
      "dollarnumb\n",
      "you\n",
      "should\n",
      "checkout\n",
      "httpaddr\n",
      "or\n",
      "perhap\n",
      "amazon\n",
      "ecnumb\n",
      "\n",
      "if\n",
      "your\n",
      "run\n",
      "someth\n",
      "big\n",
      "to\n",
      "unsubscrib\n",
      "yourself\n",
      "from\n",
      "thi\n",
      "mail\n",
      "list\n",
      "send\n",
      "an\n",
      "\n",
      "email\n",
      "to\n",
      "emailaddr\n",
      "\n",
      "\n",
      "=========================\n",
      "\n",
      "Word indices:  [86, 916, 794, 1077, 883, 370, 1699, 790, 1822, 1831, 883, 431, 1171, 794, 1002, 1893, 1364, 592, 1676, 238, 162, 89, 688, 945, 1663, 1120, 1062, 1699, 375, 1162, 479, 1893, 1510, 799, 1182, 1237, 810, 1895, 1440, 1547, 181, 1699, 1758, 1896, 688, 1676, 992, 961, 1477, 71, 530, 1699, 531]\n"
     ]
    }
   ],
   "source": [
    "file_contents = readFile(\"emailSample1.txt\")\n",
    "print(file_contents)\n",
    "word_indices = processEmail(file_contents)\n",
    "print(\"Word indices: \", word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector  1899\n",
      "Number of non-zero entries  45\n"
     ]
    }
   ],
   "source": [
    "features = emailFeatures(word_indices)\n",
    "print(\"Length of feature vector \", features.size)\n",
    "print(\"Number of non-zero entries \", np.sum(features>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Spam Email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat(\"spamTrain.mat\")\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(C=1.0, kernel=\"linear\")\n",
    "model.fit(X, y.ravel())\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  99.975\n"
     ]
    }
   ],
   "source": [
    "pred = np.reshape(pred, (pred.size, 1))\n",
    "print(\"Accurancy: \", np.mean(pred == y) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Xtest', 'ytest'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = loadmat(\"spamTest.mat\")\n",
    "data_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = data_test[\"Xtest\"]\n",
    "ytest = data_test[\"ytest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  97.8\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(Xtest)\n",
    "test_pred = np.reshape(test_pred, ytest.shape)\n",
    "print(\"Accurancy: \", np.mean(test_pred == ytest) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with my email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_email = readFile(\"spamSample2.txt\")\n",
    "print(my_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processed Email ====\n",
      "\n",
      "\n",
      "best\n",
      "buy\n",
      "viagra\n",
      "gener\n",
      "onlin\n",
      "viagra\n",
      "numbermg\n",
      "x\n",
      "number\n",
      "pill\n",
      "dollarnumb\n",
      "free\n",
      "\n",
      "pill\n",
      "reorder\n",
      "discount\n",
      "top\n",
      "sell\n",
      "number\n",
      "qualiti\n",
      "satisfact\n",
      "guarante\n",
      "we\n",
      "accept\n",
      "\n",
      "visa\n",
      "master\n",
      "echeck\n",
      "payment\n",
      "number\n",
      "satisfi\n",
      "custom\n",
      "httpaddr\n",
      "\n",
      "\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wi = processEmail(my_email)\n",
    "my_email_features = emailFeatures(wi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(my_email_features.T)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
