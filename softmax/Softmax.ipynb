{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import fmin_cg, minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat(\"ex3data1.mat\")\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (5000, 401)\n"
     ]
    }
   ],
   "source": [
    "# Get X\n",
    "X_raw = data['X']\n",
    "# Add ones to X_raw\n",
    "X = np.c_[np.ones(X_raw.shape[0]).T, X_raw]\n",
    "print(\"Shape of X: \", X.shape)\n",
    "# Get y\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    A = np.zeros(z.shape)\n",
    "    e_z = np.exp(z);\n",
    "    for i in range(e_z.shape[0]):\n",
    "        A[i, :] = e_z[i, :] / np.sum(e_z[i, :])\n",
    "    return A\n",
    "\n",
    "def softmaxCostFunction(theta, X, y, lamda = 0):\n",
    "    theta = np.reshape(theta, (10, 401))\n",
    "    m = X.shape[0];\n",
    "    z = X.dot(theta.T);\n",
    "    a = softmax(z);\n",
    "    \n",
    "    Y = np.zeros((m, 10));\n",
    "    for i in range(m):\n",
    "        Y[i, y[i, 0] % 10] = 1;\n",
    "    \n",
    "    J = np.mean(-Y * np.log(a));\n",
    "    J += (lamda/(2*m))*np.sum(np.square(theta[:, 1:]))\n",
    "    return J;\n",
    "\n",
    "def softmaxGradient(theta, X, y, lamda = 0):\n",
    "    theta = np.reshape(theta, (10, 401))\n",
    "    m = X.shape[0];\n",
    "    z = X.dot(theta.T);\n",
    "    a = softmax(z);\n",
    "                       \n",
    "    Y = np.zeros((m, 10));\n",
    "    for i in range(m):\n",
    "        Y[i, y[i, 0] % 10] = 1;\n",
    "\n",
    "    grad = np.dot((a - Y).T, X) / m;\n",
    "    grad[:, 1:] = grad[:, 1:] + (lamda/m) * theta[:, 1:]\n",
    "    return (grad.flatten());\n",
    "\n",
    "def softmaxStable(z):\n",
    "    A = np.zeros(z.shape)\n",
    "    e_z = np.zeros(z.shape)\n",
    "    for i in range(e_z.shape[0]):\n",
    "        e_z[i, :] = np.exp(z[i, :] - np.max(z[i, :]))\n",
    "        A[i, :] = e_z[i, :] / np.sum(e_z[i, :])\n",
    "    return A\n",
    "\n",
    "def predictSoftmaxOneVsAll(all_theta, X):\n",
    "    m, n = X.shape;\n",
    "    # X : m * n\n",
    "    # all_theta: n_label * n\n",
    "    prob = softmaxStable(X.dot(all_theta.T));\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    return pred\n",
    "\n",
    "def accuracy(pred,y):\n",
    "    pred.shape = (pred.size,1)\n",
    "    return np.mean((pred == y % 10))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.011698\n",
      "         Iterations: 100\n",
      "         Function evaluations: 308\n",
      "         Gradient evaluations: 308\n"
     ]
    }
   ],
   "source": [
    "init_theta = np.zeros((10, 401));\n",
    "lamda = 0;\n",
    "max_iters = 100;\n",
    "\n",
    "theta = fmin_cg(softmaxCostFunction,init_theta,fprime = softmaxGradient,args=(X,y,lamda), maxiter = max_iters,disp = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of softmax method  97.42\n"
     ]
    }
   ],
   "source": [
    "theta = np.reshape(theta, (10, 401))\n",
    "pre = predictSoftmaxOneVsAll(theta, X);\n",
    "print(\"Accurary of softmax method \", accuracy(pre, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
